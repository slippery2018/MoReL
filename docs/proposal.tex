\documentclass[10pt,twocolumn]{article} 
\usepackage{simpleConference}
\usepackage{authblk}
\usepackage{times}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{url,hyperref}

\begin{document}

\title{MoReL: A Toolkit for Molecule Representation Learning }


\author[ ]{Jiang, Songhao\thanks{shjiang@uchicago.edu}}
\author[ ]{Duan, Xiaotian\thanks{xduan7@uchicago.edu}}
\affil[ ]{Department of Computer Science}
\affil[ ]{The Univeristy of Chicago}

\maketitle
\thispagestyle{empty}

\begin{abstract}

There are multiple ways to featurize molecules, and more than a couple of suitable deep learning models for any one of these features. Moreover, for each one of the feature and model combination, there are different sets of hyper-parameters to explore. The combinatorial number of training instances to run is in the scale of thousands if not more, which makes it crucial to have a robust and efficient system to help us with data loading, as well as the arrangement and parallelization of the jobs. 
We are planning on implementing a light-weight toolkit, MoRel, for this purpose. 

\end{abstract}


\section{Introduction}

The properties of a molecule is at the heart of many problems, from drug synethsis to material discovery [citation]. 
With the rising popularity of deep learning and the support of underlying hardwares, more and more efforts have been put into the research of representation learning of molecules using neural networks. 
However, unlike images or natural language text, transforming molecules into vectors of numbers for statistical learning models is rather unintuitive. Different ways of featurization have been invented to counter this problem, like SMILES (Simplified molecular-input line-entry system) strings, fringerprints [citation], decriptors, and graphs. 

These ditinct molecule features are suitable for different sets of deep learning models. 
For example, SMILES strings (e.g. C02, C1CCCCC1), which are entirely made of English characters and symbols, are preferably learned with NLP (natural language processing) models like RNN [citation] or Transformer [citation]. 
Similarly, graph features of a molecule are usually feed into neural networks that are good for learning graphs, like GGNN [citation] or GCN [citation]. 

Moreover, for each feature and learning model combination, we need to try different hyper-parameters before having some notion about the performance of such combination. 
For example, for the same model and features, we would like to test with different drop out ratios and optimizers.
A model might behave badly or even unstable for one set of hyper-parameters but beat records with another set. 

The combinatorial number of training instances is at least in the scale of a few thousands. 
However, no matter which feature, model, and hyper-parameters we choose, the goal stays the same, that is, learning the correct and unique representation of a single molecule. 
This ensures a fair comparison across all the combinations, which is the most important motivation of MoReL: to build a light-weight toolkit that efficiently enables the comparison between thousands of training instances for representation of learning. 
There are a few challenges for this project:
\begin{description}
	\item[$\bullet$]  There are about 97 million molecules to train with. In the most extreme case, the features of molecules will take up to 200GB when represented as graphs. The scale makes dataloading an easy bottleneck during training;
	\item[$\bullet$]  There are only a limited number of GPUs and they are usually meant to be shared between multiple users. How to use them conservatively and efficiently is the core of this project; 
	\item[$\bullet$]  Some training instances already have working Python scripts. We would like our toolkit to ultilize the existing code with minimal changes. This will not only save a lot work, but also make MoReL easy to be used on future projects that requires hyper-parameter optimization with existing training scripts. 
\end{description}

The layout of this paper are list as follows: 
section \ref{prep} talks about some previous works that are similar or related to ours; 
section \ref{body} contains planned implementation details and estimated timeline; 
section \ref{eval} includes some possible methods to evaluate the system, which are subject to change drastically in the future. 

\section{Related Work} \label{prep}

Significant number of works have been done involving comparison between different molecule represeantion learning methods. 
For example, [citation: deeply learning molecularr ...] has evluated molecule with GGNN, GCN, and their varieties; [citation: the pacific national lab paper * 2] have tried different features and made interesting comparison on benchmarked datasets. 
However, the comparison in these works are usually not comprehensive enough to cover different featurization methods or network structures. 

More similar to our project, MoleculeNet [citation] is a framework that provides tools and environment for comparing a varity of features (fingerpints, graphs, etc.) using different learning algorithms including deep learning, by evaluating performances on benchmarked datasets (HIV [citation], MUV [citation]). 
It serves to offer a benchark that users can evaluate their models back to back to existing ones. 
Our work differs from MoleculeNet in the following aspects:
\begin{description}
	\item[$\bullet$]  MoReL focuses only on deep learning methods, with huge amount of training data. MoleculeNet is more inclusive in terms of learning algorithms, but only trained on benchmarked datasets;
	\item[$\bullet$]  MoReL is able to train multiple instances if possible, and search for the best feature/model/hyper-parameters combination. MoleculeNet has no such function;
	\item[$\bullet$]  The implementation of MoReL focus on the efficiency, and can be easily applied to any scenario that requires hyper-parameter searching; 
\end{description}


\section{Implementation} \label{body}

\subsection{Feasibility}

For the data of this project, we are using downloaded molecule InChI(The IUPAC International Chemical Identifier) from PubChem [citation], which is directly accessible from PubChem FTP server. 
RDkit is an open-source cheminformatics software, that can extract features such as SMILES strings, fingerprints, and graph structures from almost all PubChem InChI data.

Also, the nerual network implemention is half-way done. 
For most models planned in this project, we have individual scripts that takes a set of hyper-parameters and prints performance evalution. 

The most time consuming part in this project is writing a "monitor" program that does the following:
\begin{description}
	\item[$\bullet$]  Load and prepare training data;
	\item[$\bullet$]  Arrange jobs to maximize the GPU ultilization;
	\item[$\bullet$]  Save/load/synchronize deep learning jobs; 
\end{description}
All these functions are simple and self-explaintory, which justifies the feasibility of this project. 
The motivation and implemenation details of will be wriiten in \ref{projstruct}.

In terms of hardware, we have two availble machines for testing and evaluation. 
One is NVidia DGX statation (256GB RAM, 8TB SSD, 4 GPUs), shared between multiple users; the other one is a high-end PC (32GB RAM, 1TB SSD, 2 GPUs). 

\subsection{Project Structure} \label{projstruct}

The core of this project is a "monitor" process that launches other python scripts that trains and evaluates the different models. 
Our two major concerns are data and GPU ultilization.

\subsubsection*{data}
Considering the initial estimation of the scale of features, we cannot fit all the featrur

To extract different molecule features, 

As mentioned in the introduction, the challenges mainly come from huge samount of training data, and unpredicable hardware resources (number of GPUs, availble RAM). 

\textbf{Guideline 1:} A clear new important technical contribution should have been articulated by the time the reader finishes page 3 i.e., a quarter of the way through the paper.

\textbf{Guideline 2:} Every section of the paper should tell a story. Don't, however, fall into the common trap of telling the entire story of how you arrived at your results. Just tell the story of the results themselves. The story should be linear, keeping the reader engaged at every step and looking forward to the next step. There should be no significant interruptions -- those can go in the Appendix.
\\
\\
Aside from these guidelines, which apply to every paper, the structure of the body varies a lot depending on content. Important components are:

\begin{description}
  \item[$\bullet$]  Running Example: When possible, use a running example throughout the paper. It can be introduced either as a subsection at the end of the Introduction, or its own Section 2 or 3 (depending on Related Work).
  \item[$\bullet$]  Preliminaries: This section, which follows the Introduction and possibly Related Work and/or Running Example, sets up notation and terminology that is not part of the technical contribution. One important function of this section is to delineate material that's not original but is needed for the paper. Be concise -- remember Guideline 1.
    \item[$\bullet$] Content: The meat of the paper includes algorithms, system descriptions, new language constructs, analyses, etc. Whenever possible use a ``top-down" description: readers should be able to see where the material is going, and they should be able to skip ahead and still get the idea.
\end{description}


\section{Evaluations} \label{eval}

We could have an entire treatise on this topic alone and I am surely not the expert. Here are some random thoughts:

\begin{description}
  \item[$\bullet$]  Many conferences expect experiments.
  \item[$\bullet$]  It's easy to do ``hokey" or meaningless experiments, and many papers do.
  \item[$\bullet$]  It's easy to craft experiments to show your work in its best light, and most papers do.
    \item[$\bullet$]  What should performance experiments measure? Possibilities:  
    \begin{description}
  	  \item[$\bullet$] Pure running time
      \item[$\bullet$] Sensitivity to important parameters
      \item[$\bullet$] Scalability in various aspects: data size, problem complexity, ...
  \end{description}
    \item[$\bullet$]  What should performance experiments show? Possibilities:
        \begin{description}
  	  \item[$\bullet$] Absolute performance i.e., it's acceptable/usable
      \item[$\bullet$] Relative performance to naive approaches
      \item[$\bullet$] Relative performance to previous approaches
      \item[$\bullet$] Relative performance among different proposed approaches
  \end{description}
  \item[$\bullet$] 
\end{description}


\section{The Conclusions}

In general a short summarizing paragraph will do, and under no circumstances should the paragraph simply repeat material from the Abstract or Introduction. In some cases it's possible to now make the original claims more concrete, e.g., by referring to quantitative performance results.

\section{Future Work}

This material is important -- part of the value of a paper is showing how the work sets new research directions. I like bullet lists here. A couple of things to keep in mind:
\begin{description}
  \item[$\bullet$]  If you're actively engaged in follow-up work, say so. E.g.: ``We are currently extending the algorithm to... blah blah, and preliminary results are encouraging." This statement serves to mark your territory.
\item[$\bullet$]  Conversely, be aware that some researchers look to Future Work sections for research topics. My opinion is that there's nothing wrong with that -- consider it a compliment.
\end{description}

\section{The Acknowledgements}

Don't forget them or you'll have people with hurt feelings. Acknowledge anyone who contributed in any way: through discussions, feedback on drafts, implementation, etc. If in doubt about whether to include someone, include them.


\section{Citations}

Spend the effort to make all citations complete and consistent. Do not just copy random inconsistent BibTex (or other) entries from the web and call it a day. Check over your final bibliography carefully and make sure every entry looks right.

\section{Appendix A}
This is a simple sample of a document created using \LaTeX
   (specifically pdflatex) that includes a figure from the Vergil visual editor for Ptolemy II
   that was created by printing to the Acrobat Distiller to get a PDF file.
   It also illustrates a simple two-column conference paper style,
   and use of bibtex to handle bibligraphies.

This is a sample document for use with pdflatex, which is
a program that is included with the Miktex distribution
that directly produces PDF files from \LaTeX sources.
To run \LaTeX on this file, you need the following files:
\begin{enumerate}
\item templatePDF.tex (this file)
\item figure.pdf (the figure file)
\item simpleConference.sty (style file)
\item refs.bib (bibiliography file)
\end{enumerate}
\noindent
To create a PDF file, execute the following commands:
\begin{enumerate}
\item pdflatex mainTemplatePDF
\item bibtex mainTemplatePDF
\item pdflatex mainTemplatePDF
\item pdflatex mainTemplatePDF
\end{enumerate}
\noindent
Yes (strangely) it is necessary to run pdflatex three times.
The result will be a PDF file (plus several other files that \LaTeX
produces).  You will need a mechanism, of course, for executing
commands on the command line. If you are using Windows, I recommend
installing Cygwin and using its bash shell.

\section{Appendix B: How to Include Vergil Diagrams as Figures}
\iffalse
\begin{figure}[!b]
  \begin{center}
    \includegraphics[width=3.5in]{figure.pdf}
  \end{center}

  \caption{\small Figure caption. To get a figure to span two
      columns, use the environment figure* rather than figure.}
  \label{fig-label}
\end{figure}
\fi

Suppose you wish to include a figure, like that in figure \ref{fig-label}.
The simplest mechanism is to install Adobe Acrobat, which includes
a ``printer'' called ``Acrobat Distiller.'' Printing to this printer
creates a PDF file, which can be included in a document as shown
here.  To include Ptolemy II models \cite{PtolemyVol1:04},
just print to the distiller from within Vergil and reference
the PDF file in your \LaTeX document.

There is a bit more work to do, however.
The file that is produced by the distiller represents
a complete page, not the individual figure.
You can open it in using Acrobat (version 5.0 or later),
and select Document $\rightarrow$ Crop Pages from the menu.
In the resulting dialog, check ``Remove White Margins.''
Save the modified PDF file in a file and then reference
it in the \LaTeX file as shown in this example.

An alternative is to generate EPS (encapsulated postscript),
but the process is much more complex and fragile.
I recommend using pdflatex and Adobe Acrobat.

\bibliographystyle{abbrv}
\bibliography{refs}
\end{document}